{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируем колонки\n",
    "def generate_columns(n, name):\n",
    "    columns = [name+str(i) for i in range(1, n+1)]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем лишние нолики, чтобы красивее было смотреть\n",
    "def drop_zero(n, except_k):\n",
    "    cols = set(generate_columns(n, \"#host\")) | set(generate_columns(n, \"POShost\"))\n",
    "    drop = cols - {f\"#host{except_k}\", f\"POShost{except_k}\"}\n",
    "    return list(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим на конструкции по нужным столбцам и слову\n",
    "# Можно попросить показать прочерки\n",
    "# Можно задать верхнюю и нижнюю границы отношения\n",
    "# Можно дать дф, из которого надо смотреть, по умолчанию -- из файлов all_with_ratios_\n",
    "def watch_constr(n, cols=\"all\", host_of=None, bott_lim=0.0, up_lim=1.0, outhost=False, entries_lim=0, source=\"file\"):\n",
    "    if isinstance(source, pd.DataFrame):\n",
    "        df = source\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./outcome files/dev_train_test/all_start_finish/all_with_ratios_{n}.csv\", sep=\",\", low_memory=False)\n",
    "    \n",
    "    search_patt = ((df[\"ratio\"] >= bott_lim) & \n",
    "                  (df[\"ratio\"] <= up_lim) &\n",
    "                  (df[\"total_entries\"] >= entries_lim))\n",
    "    if cols == \"all\":\n",
    "        cols = [\"any\"] * n\n",
    "    for i in range(n):\n",
    "        if cols[i] != \"any\":\n",
    "            search_patt &= (df[f\"POS{i+1}\"] == cols[i])\n",
    "        if not outhost:\n",
    "            search_patt &= (df[f\"POShost{i+1}\"] != '_')\n",
    "    if host_of:\n",
    "        search_patt &= (df[f\"#host{host_of}\"] != \"0\")\n",
    "        return df[search_patt].drop(columns=drop_zero(n, host_of))\n",
    "    else:\n",
    "        return df[search_patt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Соединение\n",
    "\n",
    "**План:**\n",
    "1. Сохранить ВСЕ крутые конструкции (с отношением =>0.97) для n-грамм\n",
    "2. Для оставшихся (пока вместе с остатками от крутых) пойти в n+1-граммы\n",
    "3. Добавить к ним по слову с каждого конца (если появилась связь у добаленного, не трогаем, она потом вылезет)\n",
    "4. Сохранить из получившихся n+1-грамм крутые\n",
    "\n",
    "(про только популярные (>=20 вхождений) можно посчитать потом и сравнить с заранее преобработанными; в таком случае выбросим 966 вхождений при 3-граммах\n",
    "\n",
    "UPD: оставила столбцы с количеством вхождений, чтобы потом можно было отбирать с нужным лимитом: последний столбец -- число только хороших, а предпоследний -- вместе с плохими)\n",
    "\n",
    "\n",
    "**Вопросы:**\n",
    "\n",
    "- в тройках пока никого не склеиваю, но есть места, где можно схлопнуть контекст\n",
    "- если так объединять, то надо ли и тут записывать с минусами\n",
    "- зачем нам минусы, что даст эта полная группа?(\n",
    "- те, у кого нет с минусами, но не вылезли в 3-граммах -- это из-за связей-прочерков, т.е. снаружи.\n",
    "- пока одна конструкция -- одно подчинение (а не все связи в конструкции), но мб имеет смысл схлопнуть в одн строчку тех, кто без списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записывает в csv конструкцию + число её вхождений без лишних нулей\n",
    "# n -- разме n-граммы\n",
    "# cool -- датафрейм/список для записи\n",
    "# mode -- режим (w -- запись с нуля, a -- добавление в существующий файл)\n",
    "# all_host -- у всех ли слов есть инфа про хосты (при расширении контекста у добавленных слов нет заплаток-ноликов)\n",
    "def write_cool(n, cool, mode, file_dir, all_host=True):\n",
    "    if isinstance(cool, list):\n",
    "        cool_w = np.array(cool)\n",
    "    else:\n",
    "        cool_w = cool.to_numpy()\n",
    "    x, y = cool_w.shape\n",
    "    if all_host:\n",
    "        del_col = n - 1\n",
    "    else:\n",
    "        del_col = n - 2\n",
    "    cool_w = cool_w[cool_w != \"0\"].reshape((x, y - del_col))\n",
    "    \n",
    "    with open(file_dir + f\"/all_cool_{n}.csv\", mode, newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in cool_w:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляет из df его почти*_кусочек subdf\n",
    "# *почти -- потому что колонки не совпадают, для этого мерджим\n",
    "# Возвращает обновленный new_df\n",
    "def delete_subdf(df, subdf):\n",
    "    del_df = pd.merge(subdf, df, on=list(subdf.columns))\n",
    "    print(\"Rows to delete:\", del_df.shape[0])\n",
    "    new_df = pd.concat([df, del_df]).drop_duplicates(keep=False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Передвигает названия колонок и номера связей\n",
    "# (кажется, это проще, чем задавать для 4-грамм конструкции по условиям)\n",
    "# n -- размер n-граммы\n",
    "# df -- датафрейм, в котором нужно передвинуть колонки\n",
    "# shift_by -- на сколько значений передвинуть, по умолчанию на 1\n",
    "def shift_n(n, df, shift_by=1):\n",
    "    df.columns = [col_name[:-1] + str(int(col_name[-1]) + 1) for col_name in list(df.columns)]\n",
    "    for x in range (shift_by + 1, n + shift_by + 1):\n",
    "        df[f\"#host{x}\"] = df[f\"#host{x}\"].apply(lambda x: str(int(x) + 1) if x != \"0\" else \"0\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_3 = watch_constr(3, \"all\", bott_lim=0.97).drop([\"#construction\", \"ratio\"] + generate_columns(3, \"POShost\"), axis=1)\n",
    "cool_3.columns = list(cool_3.columns)[:-1] + [\"total_entries_all\"]\n",
    "cool_3[\"total_entries_good\"] = cool_3[\"total_entries_all\"]\n",
    "write_cool(3, cool_3, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to delete: 1972\n"
     ]
    }
   ],
   "source": [
    "# Из 4-грамм убираем уже записанные 3-граммы...\n",
    "# ...с дополнительным словом справа...\n",
    "all_4 = watch_constr(4, \"all\")\n",
    "new_all_4 = delete_subdf(all_4, cool_3.drop([\"total_entries_all\", \"total_entries_good\"], axis=1)) # удалили с добавкой справа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to delete: 1672\n"
     ]
    }
   ],
   "source": [
    "# ...и с дополнительным словом слева\n",
    "cool_3_copy = cool_3.copy(deep=True).drop([\"total_entries_all\", \"total_entries_good\"], axis=1)\n",
    "cool_3_l = shift_n(3, cool_3_copy)\n",
    "    \n",
    "new_all_4 = delete_subdf(new_all_4, cool_3_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Для записи с минусами везде ниже new_cool_4 > new_all_4\n",
    "# new_cool_4 = watch_constr(4, \"all\", bott_lim=0.97, source=new_all_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не_очень 3-граммы\n",
    "meh_3 = watch_constr(3, \"all\", up_lim=0.9699).drop([\"#construction\", \"ratio\", \"total_entries\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем контекст справа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Засширяет до хороших n+1-грамм заданные плохие n-граммы и с правым, и с левым контекстом\n",
    "# Возвращает датафрейм сжатых хороших для записи в файл и датафрейм развернутых хороших для удаления из общей массы n+1-грамм\n",
    "# bigger_n -- размер n+1-граммы, то, до чего расширили\n",
    "# meh_df -- датафрейм плохих конструкций, которые хотим улучшить (смещается вправо/влево отдельно)\n",
    "# bigger_df -- датафрейм n+1-грамм с вычетом конструкций, уже обработанных на данный момент\n",
    "# side -- right=слово добавляется справа, left=слева\n",
    "def widening_by_one(bigger_n, meh_df, bigger_df, side):\n",
    "    \n",
    "    # Для интересующих нас конструкций расширяем конекст\n",
    "    saved = pd.merge(bigger_df, meh_df, on=list(meh_df.columns)).drop(generate_columns(bigger_n, \"POShost\"), axis=1)\n",
    "    \n",
    "    # Набор и порядок колонок в зависимости от стороны контекста\n",
    "    if side == \"right\":\n",
    "        group_list = list(saved.columns[1:-4])\n",
    "        new_pos = f\"POS{bigger_n}\"\n",
    "        final_order = group_list + [f\"{new_pos}_ok\", f\"{new_pos}_minus\", \"total_entries_all\", \"total_entries_good\"]\n",
    "    elif side == \"left\":\n",
    "        group_list = list(saved.columns[3:-2])\n",
    "        new_pos = \"POS1\"\n",
    "        final_order = [f\"{new_pos}_ok\", f\"{new_pos}_minus\"] + group_list + [\"total_entries_all\", \"total_entries_good\"]\n",
    "        \n",
    "    # Слова, с которыми хорошо\n",
    "    add_pos = saved[saved[\"ratio\"] >= 0.97].groupby(group_list)[new_pos].apply(lambda pos: ','.join(pos))\n",
    "    \n",
    "    # Слова, с которыми плохо, заносим с \"_\"\n",
    "    add_minus_pos = saved[saved[\"ratio\"] < 0.9699].groupby(group_list)[new_pos].apply(lambda pos: ','.join(\"_\" + pos))\n",
    "    \n",
    "    # Соединяем получившиеся колонки\n",
    "    both_pos = pd.merge(add_pos, add_minus_pos, on=group_list,\\\n",
    "                        how=\"outer\", suffixes=('_ok', '_minus'), sort=group_list)\n",
    "    # Добавляем к ним сумму по всем вхождениям и только по хорошим\n",
    "    sum_entries = saved.groupby(group_list)[\"total_entries\"].sum()\n",
    "    bigger_cool = pd.merge(both_pos, sum_entries, on=group_list).dropna(subset=[f\"{new_pos}_ok\"])\n",
    "    sum_good_entries = saved[saved[\"ratio\"] >= 0.97].groupby(group_list)[\"total_entries\"].sum()\n",
    "    bigger_cool = pd.merge(bigger_cool, sum_good_entries, on=group_list, suffixes=('_all', '_good'))\n",
    "    \n",
    "    # Избавляемся от мультииндекса и перестраиваем колонки в нужном порядке\n",
    "    bigger_cool.reset_index(inplace=True)\n",
    "    bigger_cool = bigger_cool[final_order]\n",
    "\n",
    "    return bigger_cool, saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>#host1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>#host2</th>\n",
       "      <th>POS3</th>\n",
       "      <th>#host3</th>\n",
       "      <th>POS4_ok</th>\n",
       "      <th>POS4_minus</th>\n",
       "      <th>total_entries_all</th>\n",
       "      <th>total_entries_good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADV</td>\n",
       "      <td>2</td>\n",
       "      <td>NOUN,PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>2</td>\n",
       "      <td>ADP,ADV,PART</td>\n",
       "      <td>_VERB</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>NUM</td>\n",
       "      <td>2</td>\n",
       "      <td>DET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>PART</td>\n",
       "      <td>2</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>2</td>\n",
       "      <td>NUM,PRON</td>\n",
       "      <td>_ADJ,_ADP,_NOUN,_PUNCT</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POS1 #host1 POS2 #host2  POS3 #host3       POS4_ok              POS4_minus  \\\n",
       "0  ADJ      0  ADJ      0   ADV      2    NOUN,PUNCT                     NaN   \n",
       "1  ADJ      0  ADJ      0   AUX      2  ADP,ADV,PART                   _VERB   \n",
       "2  ADJ      0  ADJ      0   NUM      2           DET                     NaN   \n",
       "3  ADJ      0  ADJ      0  PART      2          NOUN                     NaN   \n",
       "4  ADJ      0  ADJ      0  VERB      2      NUM,PRON  _ADJ,_ADP,_NOUN,_PUNCT   \n",
       "\n",
       "   total_entries_all  total_entries_good  \n",
       "0                  3                   3  \n",
       "1                  6                   3  \n",
       "2                  1                   1  \n",
       "3                  1                   1  \n",
       "4                  9                   2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wid_3_right, saved_3_right = widening_by_one(4, meh_3, new_all_4, side=\"right\")\n",
    "wid_3_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cool(4, wid_3_right, mode=\"w\", all_host=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем контекст слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сдвигаем номера колонок\n",
    "meh_3_copy = meh_3.copy(deep=True)\n",
    "meh_3_l = shift_n(3, meh_3_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to delete: 6500\n"
     ]
    }
   ],
   "source": [
    "# Удаляем уже отобранное, потому что оно в большинстве случаев (94 из 108) дублируется!\n",
    "new_all_4 = delete_subdf(new_all_4, saved_3_right[saved_3_right[\"ratio\"] >= 0.97].drop([\"#construction\", \"ratio\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1_ok</th>\n",
       "      <th>POS1_minus</th>\n",
       "      <th>POS2</th>\n",
       "      <th>#host2</th>\n",
       "      <th>POS3</th>\n",
       "      <th>#host3</th>\n",
       "      <th>POS4</th>\n",
       "      <th>#host4</th>\n",
       "      <th>total_entries_all</th>\n",
       "      <th>total_entries_good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN,SCONJ</td>\n",
       "      <td>_ADV,_CCONJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>PART</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DET,NUM,VERB</td>\n",
       "      <td>_CCONJ,_NOUN,_PRON</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUX</td>\n",
       "      <td>_ADV,_CCONJ,_NOUN,_PRON</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ,ADV,CCONJ,DET,PROPN,SCONJ</td>\n",
       "      <td>_ADP,_NOUN,_PART,_PRON,_PUNCT,_VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>4</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         POS1_ok                           POS1_minus POS2  \\\n",
       "0                     NOUN,SCONJ                          _ADV,_CCONJ  ADJ   \n",
       "1                            ADV                                  NaN  ADJ   \n",
       "2                   DET,NUM,VERB                   _CCONJ,_NOUN,_PRON  ADJ   \n",
       "3                            AUX              _ADV,_CCONJ,_NOUN,_PRON  ADJ   \n",
       "4  ADJ,ADV,CCONJ,DET,PROPN,SCONJ  _ADP,_NOUN,_PART,_PRON,_PUNCT,_VERB  ADJ   \n",
       "\n",
       "  #host2 POS3 #host3   POS4 #host4  total_entries_all  total_entries_good  \n",
       "0      0  ADJ      0    AUX      3                  6                   3  \n",
       "1      0  ADJ      0   PART      3                  1                   1  \n",
       "2      0  ADJ      0   PRON      3                  6                   3  \n",
       "3      0  ADJ      0   VERB      3                  8                   1  \n",
       "4      0  ADJ      4  PROPN      0                 60                  19  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wid_3_left, saved_3_left = widening_by_one(4, meh_3_l, new_all_4, side=\"left\")\n",
    "wid_3_left.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cool(4, wid_3_left, mode=\"a\", all_host=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дописываем оставшиеся хорошие 4-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to delete: 3781\n"
     ]
    }
   ],
   "source": [
    "pure_cool_4 = delete_subdf(new_all_4, saved_3_left[saved_3_left[\"ratio\"] >= 0.97].drop([\"#construction\", \"ratio\"], axis=1))\n",
    "pure_cool_4 = pure_cool_4[pure_cool_4[\"ratio\"] >= 0.97]\n",
    "pure_cool_4.columns = list(pure_cool_4.columns)[:-1] + [\"total_entries_all\"]\n",
    "pure_cool_4[\"total_entries_good\"] = pure_cool_4[\"total_entries_all\"]\n",
    "write_cool(4, pure_cool_4.drop([\"#construction\", \"ratio\"] + generate_columns(4, \"POShost\"), axis=1), mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    377\n",
       "1    259\n",
       "Name: #host4, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_cool_4[\"#host4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение готовых конструкций\n",
    "def read_ready(csvfile, lim_all=0, lim_good=0):\n",
    "    ready = []\n",
    "    with open(csvfile, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            if int(row[-1]) >= lim_good and int(row[-2]) >= lim_all:\n",
    "                line = []\n",
    "                for word in row[:-2]:\n",
    "                    if word == \"nan\":\n",
    "                        pass\n",
    "                    elif \",\" in word:\n",
    "                        word_list = word.split(',')\n",
    "                        line.append(word_list)\n",
    "                    else:\n",
    "                        line.append(word)\n",
    "                ready.append(line)         \n",
    "    return ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ADJ', 'ADJ', 'ADV', '2', ['NOUN', 'PUNCT']],\n",
       " ['ADJ', 'ADJ', 'AUX', '2', ['ADP', 'ADV', 'PART'], '_VERB'],\n",
       " ['ADJ', 'ADJ', 'NUM', '2', 'DET'],\n",
       " ['ADJ', 'ADJ', 'PART', '2', 'NOUN'],\n",
       " ['ADJ',\n",
       "  'ADJ',\n",
       "  'VERB',\n",
       "  '2',\n",
       "  ['NUM', 'PRON'],\n",
       "  ['_ADJ', '_ADP', '_NOUN', '_PUNCT']]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_ready(\"./outcome files/...../all_cool_4.csv\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
