{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sents(test=True):\n",
    "    list_of_conllus = [\"./syntagrus/ru_syntagrus-ud-dev.conllu\",\n",
    "                       \"./syntagrus/ru_syntagrus-ud-train.conllu\",\n",
    "                      \"./syntagrus/ru_syntagrus-ud-test.conllu\"]\n",
    "    if test:\n",
    "        list_of_conllus = [\"./syntagrus/ru_syntagrus-ud-test.conllu\"]\n",
    "\n",
    "    sents = []\n",
    "    for conllu_file in list_of_conllus:\n",
    "        with open(conllu_file, encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        sents_one_file = []\n",
    "        for line in lines:\n",
    "            if line == \"\\n\":\n",
    "                s.append((\"#\", \"_\")) # маркер конца предложения\n",
    "                sents_one_file.append(s)\n",
    "            elif line.startswith('# text'): \n",
    "                s = [(\"#\", \"_\")] # маркер начала предложения\n",
    "            elif not(line.startswith('# sent_id')):\n",
    "                word = line.split('\\t')\n",
    "                if '.' not in word[0]: # удалила строчки-подпорки для опущенных слов, т.к. они очень мешают дальше, а для нашей задачи пользы не несут\n",
    "                    pos_word = word[3]\n",
    "                    num_head = word[6]\n",
    "                    if all([(num_head != \"_\"), (num_head != \"0\")]):\n",
    "                        num_head = str(int(num_head) + 1)\n",
    "                    s.append((pos_word, num_head)) # добавляем чр, номер хоста (номер слова, словоформу -- word[0], word[1])\n",
    "        \n",
    "        sents.extend(sents_one_file)\n",
    "\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams(n, sent): \n",
    "    n_grams = []\n",
    "    for i in range(n, len(sent) + 1):\n",
    "        slice_ = sent[i - n : i]\n",
    "        gram = []\n",
    "        for word in slice_:\n",
    "            pos_word = word[0]\n",
    "            num_head = word[1]\n",
    "            if num_head == '_' or int(num_head) not in range(i + 1 - n, i + 1):\n",
    "                num_head = '_'\n",
    "            else:\n",
    "                num_head = int(num_head) - (i - n)\n",
    "            gram.extend([pos_word, str(num_head)])\n",
    "        n_grams.append(tuple(gram))\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Правильный порядок для записи\n",
    "def right_col_order(n):\n",
    "    right_order = []\n",
    "    for pos, host in zip(generate_columns(n, \"POS\"), generate_columns(n, \"#host\")):\n",
    "        right_order.extend([pos, host])\n",
    "    return right_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем колонки по шаблону\n",
    "def generate_columns(n, name):\n",
    "    columns = [name+str(i) for i in range(1, n+1)]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def got(i, row):\n",
    "    if row[f\"#host{i}_y\"] == \"0\":\n",
    "        return \"0\"\n",
    "    elif row[f\"#host{i}_x\"] == row[f\"#host{i}_y\"]:\n",
    "        # -1 -- сдвиг по списку\n",
    "        return str(int(row[\"index\"]) + i - 1)\n",
    "    else:\n",
    "        return str(int(row[\"index\"]) + i - 1) + \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_T_F(test=True):\n",
    "    all_sents = get_sents(test=test)\n",
    "    if test:\n",
    "        path = \"./outcome files/dev_train/all_start_finish/\"\n",
    "    else:\n",
    "        path = \"./outcome files/dev_train_test/\"\n",
    "    count = {\n",
    "             3: {\"True\": 0, \"False\": 0}, \n",
    "             4: {\"True\": 0, \"False\": 0},\n",
    "#              5: {\"True\": 0, \"False\": 0},\n",
    "#              6: {\"True\": 0, \"False\": 0},\n",
    "             \"all_n\": {\"True\": 0, \"False\": 0},\n",
    "             \"all\": 0\n",
    "            }\n",
    "    for sent in tqdm(all_sents):\n",
    "        n_elem = len(sent)\n",
    "        all_sent_links = [\"*\"] * n_elem\n",
    "        count[\"all\"] += (n_elem - 3)\n",
    "\n",
    "        for n in range(3, 5):\n",
    "            sent_links = [\"*\"] * n_elem\n",
    "            df = pd.read_csv(path + f\"all_cool_{n}_grouped.csv\", sep=\",\", low_memory=False)\n",
    "            df = df[df[\"total_entries\"] > 50]\n",
    "            sent_n = get_n_grams(n, sent)\n",
    "            df_sent = pd.DataFrame(sent_n, columns=right_col_order(n))\n",
    "            df_sent.reset_index(level=0, inplace=True)\n",
    "            df_m = pd.merge(df_sent, df, on=generate_columns(n, \"POS\")).astype(str)\n",
    "\n",
    "            if not df_m.empty:\n",
    "                col_np = []\n",
    "                for i in range(1, n+1):\n",
    "                    df_m[f\"got_{i}\"] = df_m.apply(lambda row: got(i, row), axis=1)\n",
    "                    col_np.append(f\"got_{i}\")\n",
    "                nump = df_m[col_np].to_numpy()\n",
    "                nums_word = np.unique(nump, return_counts=True)[0][1:]\n",
    "                \n",
    "                # Расставляем теги в предложении при анализе только этой ширины n-грамм\n",
    "                for i in nums_word:\n",
    "                    if i[-1] == \"*\":\n",
    "                        sent_links[int(i[:-1])] = \"False\"\n",
    "                    else:\n",
    "                        sent_links[int(i)] = \"True\"\n",
    "                        \n",
    "                # Добавляем к счётчику данные с этой ширины n-грамм\n",
    "                count_sent_n = Counter(sent_links)\n",
    "                count[n][\"True\"] += count_sent_n[\"True\"]\n",
    "                count[n][\"False\"] += count_sent_n[\"False\"]\n",
    "                \n",
    "                # Обновляем итоговые разбор предложения\n",
    "                for i in nums_word:\n",
    "                    if i[-1] == \"*\":\n",
    "                        all_sent_links[int(i[:-1])] = \"False\"\n",
    "                    else:\n",
    "                        all_sent_links[int(i)] = \"True\"\n",
    "                        \n",
    "        # Добавляем к общему счетчику\n",
    "        count_sent = Counter(all_sent_links)\n",
    "        count[\"all_n\"][\"True\"] += count_sent[\"True\"]\n",
    "        count[\"all_n\"][\"False\"] += count_sent[\"False\"]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(n, count):\n",
    "    precision = count[n][\"True\"] / (count[n][\"True\"] + count[n][\"False\"])\n",
    "    cover = (count[n][\"True\"] + count[n][\"False\"]) / count[\"all\"]\n",
    "    return precision, cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(text, test=True):\n",
    "    if test:\n",
    "        path = \"./outcome files/dev_train/\"\n",
    "    else:\n",
    "        path = \"./outcome files/dev_train_test/\"\n",
    "    with open(path + \"quality.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(test=False):\n",
    "    count = count_T_F(test=test)\n",
    "    \n",
    "    sum_true = 0\n",
    "    sum_false = 0\n",
    "    for n in range(3, 5):\n",
    "        precision, cover = metrics(n, count)\n",
    "        sum_true += count[n][\"True\"]\n",
    "        sum_false += count[n][\"False\"]\n",
    "\n",
    "        text = f\"Для {n}-грамм:\\nточность {precision}\\nпокрытие {cover}\\n\\n\"\n",
    "        write(text, test=test)\n",
    "\n",
    "    total_prec = sum_true / (sum_true + sum_false)\n",
    "    total_cov = (sum_true + sum_false) / count[\"all\"]\n",
    "    total_text = f\"Всего:\\nточность {total_prec}\\nпокрытие {total_cov}\\n\\n\"\n",
    "    write(total_text, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6491/6491 [09:33<00:00, 11.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# На test\n",
    "run_all(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/61889 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./outcome files/dev_train_test/all_cool_3_grouped.csv does not exist: './outcome files/dev_train_test/all_cool_3_grouped.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6ca64cab2ae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# На всей коллекции\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-9450a21769a0>\u001b[0m in \u001b[0;36mrun_all\u001b[1;34m(test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_T_F\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msum_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msum_false\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-a5cbcdee4617>\u001b[0m in \u001b[0;36mcount_T_F\u001b[1;34m(test)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0msent_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_elem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf\"all_cool_{n}_grouped.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"total_entries\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0msent_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_n_grams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\барабек\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\барабек\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\барабек\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\барабек\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\барабек\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ./outcome files/dev_train_test/all_cool_3_grouped.csv does not exist: './outcome files/dev_train_test/all_cool_3_grouped.csv'"
     ]
    }
   ],
   "source": [
    "# На всей коллекции\n",
    "run_all(test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** = число верно определенных / число тех, на которые хоть что-то сказал (= верно + неверно)\n",
    "\n",
    "**Recall** = число верно определенных / число связей (= элементов - корень - концы?)\n",
    "\n",
    "\n",
    "! Не буду пользоваться этими терминами, тк они -- про бинарную классификацию, а у меня другая\n",
    "\n",
    "Многоклассовая и микроусреднение -- не прокатит для общей оценки\n",
    "\n",
    "А что у меня? Классификация с неопределенным кол-вом классов? И для каждого предложения разное количество классов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исправление к курсовой (курсивом то, что мы хотели описать в терминах формул):\n",
    "\n",
    "В действительности мы не можем применять метрики precision и recall, так как мы имеем дело не с бинарной классификацией, а с многоклассовой. При этом число классов (то есть число возможных вершин) определяется для каждого преложения отдельно. В связи с этим для оценки качества нашего метода введём следующие метрики:\n",
    "\n",
    "- Покрытие = число хоть как-то определённых связей во всех предложениях *(ТР + FP)* / число связей во всех предложений *(TP + FP + **TN + FN**)*\n",
    "- \"Точность\" = число верно определённых связей во всех предложениях *(ТР)* / число связей, которые рассматривались в конструкциях *(TP + FP)*\n",
    "- Тогда **TN + FN** -- число не рассматриваемых связей, то есть не различаем TN и FN, то есть не можем посчитать \"recall\".\n",
    "\n",
    "? Как переназвать \"точность\" ? Или истовить слово \"точность\", но вот просто написать, что мы под ним имеем в виду? (Не верится, что модели такого типа никогда ни у кого не было и что для такого еще не придумали отдельного слова(( )\n",
    "\n",
    "- хотим померить долю текста, для которой мы можем высказать гипотезу\n",
    "- и точность высказываемой гипотезы\n",
    "- ! у spaCy precision = accuracy, тк полнота 100%\n",
    "\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./outcome files/dev_train/all_start_finish/all_cool_3_grouped.csv\", sep=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=\"total_entries\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_sorted.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>#host1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>#host2</th>\n",
       "      <th>POS3</th>\n",
       "      <th>#host3</th>\n",
       "      <th>total_entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>3</td>\n",
       "      <td>AUX</td>\n",
       "      <td>3</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS1  #host1 POS2  #host2  POS3  #host3  total_entries\n",
       "114  CCONJ       3  AUX       3  VERB       0             42"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted[(df_sorted[\"POS1\"] == \"CCONJ\") &\n",
    "          (df_sorted[\"POS2\"] == \"AUX\") &\n",
    "          (df_sorted[\"POS3\"] == \"VERB\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>#host1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>#host2</th>\n",
       "      <th>POS3</th>\n",
       "      <th>#host3</th>\n",
       "      <th>total_entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>0</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>1</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>ADV</td>\n",
       "      <td>3</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>SYM</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>SYM</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     POS1  #host1   POS2  #host2   POS3  #host3  total_entries\n",
       "423  INTJ       0  PUNCT       1  SCONJ       0              1\n",
       "424  NOUN       2    ADV       3    SYM       0              1\n",
       "425  NOUN       2   INTJ       0  PUNCT       2              1\n",
       "426  NOUN       0    SYM       3   NOUN       1              1\n",
       "427  VERB       0   VERB       1    SYM       2              1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
