{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В действительности мы не можем применять метрики *precision* и *recall*, так как мы имеем дело не с бинарной классификацией, а с многоклассовой. При этом число классов (то есть число возможных вершин) определяется для каждого преложения отдельно. В связи с этим для оценки качества нашего метода введём следующие метрики:\n",
    "\n",
    "- Покрытие = число хоть как-то определённых связей во всех предложениях *(ТР + FP)* / число связей во всех предложений *(TP + FP + **TN + FN**)*\n",
    "- \"Точность\" = число верно определённых связей во всех предложениях *(ТР)* / число связей, которые рассматривались в конструкциях *(TP + FP)*\n",
    "- Тогда **TN + FN** -- число не рассматриваемых связей, то есть не различаем TN и FN, то есть не можем посчитать \"recall\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Осторожно!* Код считается довольно долго (часов 6-7). Раскомменьте последние ячейки для запуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sents(test=True):\n",
    "    list_of_conllus = [\"./syntagrus/ru_syntagrus-ud-dev.conllu\",\n",
    "                       \"./syntagrus/ru_syntagrus-ud-train.conllu\",\n",
    "                      \"./syntagrus/ru_syntagrus-ud-test.conllu\"]\n",
    "    if test:\n",
    "        list_of_conllus = [\"./syntagrus/ru_syntagrus-ud-test.conllu\"]\n",
    "\n",
    "    sents = []\n",
    "    for conllu_file in list_of_conllus:\n",
    "        with open(conllu_file, encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        sents_one_file = []\n",
    "        for line in lines:\n",
    "            if line == \"\\n\":\n",
    "                s.append((\"#\", \"_\")) # маркер конца предложения\n",
    "                sents_one_file.append(s)\n",
    "            elif line.startswith('# text'): \n",
    "                s = [(\"#\", \"_\")] # маркер начала предложения\n",
    "            elif not(line.startswith('# sent_id')):\n",
    "                word = line.split('\\t')\n",
    "                if '.' not in word[0]: # удалила строчки-подпорки для опущенных слов, т.к. они очень мешают дальше, а для нашей задачи пользы не несут\n",
    "                    pos_word = word[3]\n",
    "                    num_head = word[6]\n",
    "                    if all([(num_head != \"_\"), (num_head != \"0\")]):\n",
    "                        num_head = str(int(num_head) + 1)\n",
    "                    s.append((pos_word, num_head)) # добавляем чр, номер хоста (номер слова, словоформу -- word[0], word[1])\n",
    "        \n",
    "        sents.extend(sents_one_file)\n",
    "\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams(n, sent): \n",
    "    n_grams = []\n",
    "    for i in range(n, len(sent) + 1):\n",
    "        slice_ = sent[i - n : i]\n",
    "        gram = []\n",
    "        for word in slice_:\n",
    "            pos_word = word[0]\n",
    "            num_head = word[1]\n",
    "            if num_head == '_' or int(num_head) not in range(i + 1 - n, i + 1):\n",
    "                num_head = '_'\n",
    "            else:\n",
    "                num_head = int(num_head) - (i - n)\n",
    "            gram.extend([pos_word, str(num_head)])\n",
    "        n_grams.append(tuple(gram))\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Правильный порядок для записи\n",
    "def right_col_order(n):\n",
    "    right_order = []\n",
    "    for pos, host in zip(generate_columns(n, \"POS\"), generate_columns(n, \"#host\")):\n",
    "        right_order.extend([pos, host])\n",
    "    return right_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем колонки по шаблону\n",
    "def generate_columns(n, name):\n",
    "    columns = [name+str(i) for i in range(1, n+1)]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def got(i, row):\n",
    "    if row[f\"#host{i}_y\"] == \"0\":\n",
    "        return \"0\"\n",
    "    elif row[f\"#host{i}_x\"] == row[f\"#host{i}_y\"]:\n",
    "        # -1 -- сдвиг по списку\n",
    "        return str(int(row[\"index\"]) + i - 1)\n",
    "    else:\n",
    "        return str(int(row[\"index\"]) + i - 1) + \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_T_F(test=True):\n",
    "    all_sents = get_sents(test=test)\n",
    "    if test:\n",
    "        path = \"./outcome files/dev_train/all_start_finish/\"\n",
    "    else:\n",
    "        path = \"./outcome files/dev_train_test/\"\n",
    "    count = {\n",
    "             3: {\"True\": 0, \"False\": 0}, \n",
    "             4: {\"True\": 0, \"False\": 0},\n",
    "             5: {\"True\": 0, \"False\": 0},\n",
    "             6: {\"True\": 0, \"False\": 0},\n",
    "             \"all_n\": {\"True\": 0, \"False\": 0},\n",
    "             \"all\": 0\n",
    "            }\n",
    "    for sent in tqdm(all_sents):\n",
    "        n_elem = len(sent)\n",
    "        all_sent_links = [\"*\"] * n_elem\n",
    "        count[\"all\"] += (n_elem - 3)\n",
    "\n",
    "        for n in range(3, 7):\n",
    "            sent_links = [\"*\"] * n_elem\n",
    "            df = pd.read_csv(path + f\"all_cool_{n}_grouped.csv\", sep=\",\", low_memory=False)\n",
    "            df = df[df[\"total_entries\"] > 50]\n",
    "            sent_n = get_n_grams(n, sent)\n",
    "            df_sent = pd.DataFrame(sent_n, columns=right_col_order(n))\n",
    "            df_sent.reset_index(level=0, inplace=True)\n",
    "            df_m = pd.merge(df_sent, df, on=generate_columns(n, \"POS\")).astype(str)\n",
    "\n",
    "            if not df_m.empty:\n",
    "                col_np = []\n",
    "                for i in range(1, n+1):\n",
    "                    df_m[f\"got_{i}\"] = df_m.apply(lambda row: got(i, row), axis=1)\n",
    "                    col_np.append(f\"got_{i}\")\n",
    "                nump = df_m[col_np].to_numpy()\n",
    "                nums_word = np.unique(nump, return_counts=True)[0][1:]\n",
    "                \n",
    "                # Расставляем теги в предложении при анализе только этой ширины n-грамм\n",
    "                for i in nums_word:\n",
    "                    if i[-1] == \"*\":\n",
    "                        sent_links[int(i[:-1])] = \"False\"\n",
    "                    else:\n",
    "                        sent_links[int(i)] = \"True\"\n",
    "                        \n",
    "                # Добавляем к счётчику данные с этой ширины n-грамм\n",
    "                count_sent_n = Counter(sent_links)\n",
    "                count[n][\"True\"] += count_sent_n[\"True\"]\n",
    "                count[n][\"False\"] += count_sent_n[\"False\"]\n",
    "                \n",
    "                # Обновляем итоговые разбор предложения\n",
    "                for i in nums_word:\n",
    "                    if i[-1] == \"*\":\n",
    "                        all_sent_links[int(i[:-1])] = \"False\"\n",
    "                    else:\n",
    "                        all_sent_links[int(i)] = \"True\"\n",
    "                        \n",
    "        # Добавляем к общему счетчику\n",
    "        count_sent = Counter(all_sent_links)\n",
    "        count[\"all_n\"][\"True\"] += count_sent[\"True\"]\n",
    "        count[\"all_n\"][\"False\"] += count_sent[\"False\"]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(n, count):\n",
    "    precision = count[n][\"True\"] / (count[n][\"True\"] + count[n][\"False\"])\n",
    "    cover = (count[n][\"True\"] + count[n][\"False\"]) / count[\"all\"]\n",
    "    return precision, cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(text, test=True):\n",
    "    if test:\n",
    "        path = \"./outcome files/dev_train/\"\n",
    "    else:\n",
    "        path = \"./outcome files/dev_train_test/\"\n",
    "    with open(path + \"quality.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(test=False):\n",
    "    count = count_T_F(test=test)\n",
    "    \n",
    "    sum_true = 0\n",
    "    sum_false = 0\n",
    "    for n in range(3, 7):\n",
    "        precision, cover = metrics(n, count)\n",
    "        sum_true += count[n][\"True\"]\n",
    "        sum_false += count[n][\"False\"]\n",
    "\n",
    "        text = f\"Для {n}-грамм:\\nточность {precision}\\nпокрытие {cover}\\n\\n\"\n",
    "        write(text, test=test)\n",
    "\n",
    "    total_prec = sum_true / (sum_true + sum_false)\n",
    "    total_cov = (sum_true + sum_false) / count[\"all\"]\n",
    "    total_text = f\"Всего:\\nточность {total_prec}\\nпокрытие {total_cov}\\n\\n\"\n",
    "    write(total_text, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На test\n",
    "# run_all(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # На всей коллекции\n",
    "# run_all(test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
